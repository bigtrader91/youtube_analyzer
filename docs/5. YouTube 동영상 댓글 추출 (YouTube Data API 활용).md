### **개발 문서 5: YouTube 동영상 댓글 추출 (YouTube Data API 활용)**

**1. 모듈 목표:**

*   YouTube Data API v3의 `commentThreads.list` 엔드포인트를 사용하여 특정 YouTube 동영상의 최상위 댓글(Top-level comments) 및 해당 댓글의 답글(Replies)을 수집하는 파이썬 모듈 개발.
*   추출된 댓글 텍스트 데이터를 후속 NLP 분석(키워드 추출, 감성 분석 등)에 적합한 형태로 가공 및 저장.
*   댓글 기능이 비활성화되었거나 댓글이 없는 경우 등 예외 상황 처리.

**2. 핵심 API 엔드포인트:**

*   **`commentThreads.list`:** 특정 동영상 또는 채널의 최상위 댓글 스레드를 가져옴. 댓글 텍스트, 작성자 정보, 작성일, 좋아요 수 등을 포함. 답글 존재 여부 확인 가능.
*   **(선택) `comments.list`:** `commentThreads.list`에서 얻은 최상위 댓글 ID(`topLevelComment.id`)를 `parentId`로 지정하여 해당 댓글의 답글(replies)을 가져옴.

**3. 필수 입력:**

*   YouTube Data API 키 (개발 문서 1에서 생성)
*   `video_id`: 댓글을 추출할 YouTube 동영상 ID (e.g., `dQw4w9WgXcQ`). 개발 문서 3 또는 4에서 사용된 ID.
*   (선택) `max_results_per_page`: 페이지당 가져올 댓글 스레드 수 (최대 100, 기본 20).
*   (선택) `max_total_comments`: 수집할 총 최대 댓글 수 (최상위 댓글 기준). 너무 많으면 API 할당량 소모 및 처리 시간 증가.
*   (선택) `order`: 댓글 정렬 방식 (`time` (최신순) 또는 `relevance` (인기순, 기본값)).
*   (선택) `fetch_replies`: 답글까지 수집할지 여부 (True/False). 답글 수집은 추가 API 호출 필요.

**4. 주요 구현 단계:**

*   **(1) YouTube API 클라이언트 빌드:**
    *   `googleapiclient.discovery.build` 함수 사용 (개발 문서 3과 동일).
*   **(2) 최상위 댓글 스레드 요청 (`commentThreads.list`) 생성 및 실행:**
    *   `youtube.commentThreads().list()` 메서드 호출 준비.
    *   `part` 매개변수 설정: `snippet` (댓글 내용, 작성자 정보, 게시일 등 포함), `replies` (답글 정보 포함 시).
    *   `videoId` 매개변수에 대상 동영상 ID 설정.
    *   `textFormat` 매개변수 설정: `plainText` (HTML 태그 제외).
    *   필요에 따라 `maxResults`, `order` 등 선택적 매개변수 설정.
*   **(3) 페이징 처리 (최상위 댓글):**
    *   `search.list`와 유사하게, 응답에 `nextPageToken`이 있으면 이를 다음 요청의 `pageToken`으로 사용하여 모든 최상위 댓글 스레드를 가져올 때까지 반복 (또는 `max_total_comments` 도달 시 중단).
*   **(4) 최상위 댓글 데이터 추출:**
    *   응답 객체의 `items` 리스트 순회.
    *   각 `item['snippet']['topLevelComment']['snippet']`에서 필요한 정보 추출:
        *   `textDisplay` 또는 `textOriginal`: 댓글 텍스트
        *   `authorDisplayName`: 작성자 이름
        *   `publishedAt`: 작성일
        *   `updatedAt`: 수정일
        *   `likeCount`: 좋아요 수
        *   `totalReplyCount`: 해당 댓글의 답글 수 (`part='replies'` 포함 시)
        *   `item['snippet']['topLevelComment']['id']`: 최상위 댓글 ID (답글 조회 시 사용)
*   **(5) (선택) 답글 요청 (`comments.list`) 생성 및 실행:**
    *   `fetch_replies`가 True이고 `totalReplyCount` > 0 인 경우 실행.
    *   `youtube.comments().list()` 메서드 호출 준비.
    *   `part` 매개변수 설정: `snippet` (답글 내용, 작성자 등).
    *   `parentId` 매개변수에 해당 최상위 댓글 ID (`item['snippet']['topLevelComment']['id']`) 설정.
    *   `textFormat` 매개변수 설정: `plainText`.
    *   `maxResults` 설정 (최대 100).
    *   답글도 페이징 처리가 필요할 수 있음 (`nextPageToken` 확인).
*   **(6) 답글 데이터 추출:**
    *   `comments.list` 응답의 `items` 리스트 순회.
    *   각 `item['snippet']`에서 댓글 텍스트, 작성자, 작성일 등 추출.
*   **(7) 데이터 구조화:**
    *   최상위 댓글과 해당 답글 정보를 포함하는 구조로 데이터 구성. 리스트(List of Dictionaries) 또는 Pandas DataFrame 사용.
    *   예시 구조: `[{'commentId': 'top_level_id', 'text': '최상위 댓글 내용', 'author': '작성자', 'publishedAt': '...', 'likeCount': 10, 'replyCount': 2, 'replies': [{'commentId': 'reply_id_1', 'text': '답글 내용 1', ...}, {'commentId': 'reply_id_2', 'text': '답글 내용 2', ...}]}, ...]`

**5. 코드 스니펫 예시 (핵심 로직):**

```python
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import pandas as pd
import time

# --- 설정값 (예시) ---
API_KEY = "YOUR_YOUTUBE_API_KEY"
VIDEO_ID = "ogfYd705cRs" # 댓글 추출 대상 비디오 ID
MAX_TOTAL_COMMENTS = 200 # 수집할 최대 최상위 댓글 수
FETCH_REPLIES = True # 답글도 수집할지 여부
MAX_REPLIES_PER_COMMENT = 10 # 각 댓글당 최대 답글 수 (API 호출 제한 목적)

def get_video_comments(api_key, video_id, max_total_comments, fetch_replies=True, max_replies_per_comment=10):
    """YouTube Data API를 사용하여 동영상 댓글(및 답글)을 추출합니다."""
    youtube = build("youtube", "v3", developerKey=api_key)
    all_comments_data = []
    next_page_token = None

    print(f"비디오 ID '{video_id}'의 댓글 추출 시작...")

    while len(all_comments_data) < max_total_comments:
        try:
            # 최상위 댓글 요청
            request = youtube.commentThreads().list(
                part="snippet,replies" if fetch_replies else "snippet",
                videoId=video_id,
                textFormat="plainText",
                order="relevance", # 또는 "time"
                maxResults=min(100, max_total_comments - len(all_comments_data)), # 페이지당 최대 100개
                pageToken=next_page_token
            )
            response = request.execute()

            for item in response.get("items", []):
                top_comment_snippet = item['snippet']['topLevelComment']['snippet']
                comment_data = {
                    'commentId': item['snippet']['topLevelComment']['id'],
                    'text': top_comment_snippet['textDisplay'],
                    'author': top_comment_snippet['authorDisplayName'],
                    'publishedAt': top_comment_snippet['publishedAt'],
                    'updatedAt': top_comment_snippet['updatedAt'],
                    'likeCount': top_comment_snippet['likeCount'],
                    'totalReplyCount': item['snippet']['totalReplyCount'] if 'totalReplyCount' in item['snippet'] else 0,
                    'replies': []
                }

                # 답글 수집 로직 (선택 사항)
                if fetch_replies and comment_data['totalReplyCount'] > 0:
                    print(f"  댓글 ID '{comment_data['commentId']}'의 답글({comment_data['totalReplyCount']}개) 수집 시도...")
                    replies_data, failed_replies = get_comment_replies(
                        youtube,
                        comment_data['commentId'],
                        min(comment_data['totalReplyCount'], max_replies_per_comment) # 너무 많은 답글 제한
                    )
                    comment_data['replies'] = replies_data
                    if failed_replies:
                         print(f"    답글 수집 중 일부 오류 발생 (댓글 ID: {comment_data['commentId']})")

                all_comments_data.append(comment_data)
                if len(all_comments_data) >= max_total_comments:
                    break # 목표 수 도달 시 중단

            next_page_token = response.get("nextPageToken")
            print(f"현재까지 수집된 최상위 댓글 수: {len(all_comments_data)}")

            if not next_page_token:
                print("더 이상 댓글 페이지가 없습니다.")
                break

            # API 할당량 고려 지연 추가
            time.sleep(0.5)

        except HttpError as e:
            print(f"API 요청 중 오류 발생: {e}")
            if e.resp.status == 403:
                if 'commentsDisabled' in str(e):
                     print("오류: 이 동영상에는 댓글 기능이 비활성화되어 있습니다.")
                else:
                     print("오류 403: 할당량 초과 또는 API 키/권한 문제일 수 있습니다.")
            break # 오류 발생 시 중단
        except Exception as e:
            print(f"알 수 없는 오류 발생: {e}")
            break

    print(f"총 {len(all_comments_data)}개의 최상위 댓글 스레드를 수집했습니다.")
    return all_comments_data

def get_comment_replies(youtube, parent_id, max_results):
    """주어진 부모 댓글 ID에 대한 답글을 가져옵니다."""
    replies_data = []
    failed = False
    next_page_token = None

    while len(replies_data) < max_results:
        try:
            current_max = min(100, max_results - len(replies_data)) # 페이지당 최대 100개
            if current_max <= 0: break

            request = youtube.comments().list(
                part="snippet",
                parentId=parent_id,
                textFormat="plainText",
                maxResults=current_max,
                pageToken=next_page_token
            )
            response = request.execute()

            for item in response.get("items", []):
                snippet = item['snippet']
                replies_data.append({
                    'commentId': item['id'],
                    'text': snippet['textDisplay'],
                    'author': snippet['authorDisplayName'],
                    'publishedAt': snippet['publishedAt'],
                    'updatedAt': snippet['updatedAt'],
                    'likeCount': snippet['likeCount']
                })
                if len(replies_data) >= max_results: break

            next_page_token = response.get("nextPageToken")
            if not next_page_token: break
            time.sleep(0.3) # 답글 페이징 지연

        except HttpError as e:
            print(f"    답글 조회 중 오류 (Parent ID: {parent_id}): {e}")
            failed = True
            break
        except Exception as e:
            print(f"    답글 조회 중 알 수 없는 오류 (Parent ID: {parent_id}): {e}")
            failed = True
            break

    return replies_data, failed


# --- 실행 흐름 (예시) ---
if __name__ == "__main__":
    comments_result = get_video_comments(API_KEY, VIDEO_ID, MAX_TOTAL_COMMENTS, FETCH_REPLIES, MAX_REPLIES_PER_COMMENT)

    if comments_result:
        # 결과를 DataFrame으로 변환 (답글은 리스트 형태로 유지하거나, 별도 처리 필요)
        df_comments = pd.DataFrame(comments_result)
        # 답글을 보기 쉽게 처리하려면 추가 작업 필요 (예: json normalize 또는 별도 테이블 생성)
        print("\n--- 추출된 댓글 (최상위 댓글 기준) ---")
        print(df_comments[['commentId', 'text', 'author', 'likeCount', 'totalReplyCount']].head())

        # 모든 텍스트 데이터 (최상위 + 답글) 추출 예시
        all_text = []
        for comment in comments_result:
            all_text.append(comment['text'])
            for reply in comment.get('replies', []):
                all_text.append(reply['text'])

        print(f"\n--- 총 {len(all_text)}개의 댓글/답글 텍스트 추출 ---")
        # print(all_text[:10]) # 처음 10개 텍스트 출력

        # df_comments.to_json("video_comments.json", orient="records", lines=True, force_ascii=False)
```

**6. 데이터 출력:**

*   모듈은 수집된 댓글 정보(최상위 댓글 및 선택적으로 답글)를 담은 **리스트(List of Dictionaries)** 또는 **Pandas DataFrame**을 반환. 각 딕셔너리는 하나의 최상위 댓글 스레드를 나타내며, 답글 정보는 내포된 리스트 형태로 포함될 수 있음.
*   NLP 분석을 위해 모든 댓글 텍스트(최상위+답글)만 추출하여 리스트 형태로 반환할 수도 있음.

**7. 오류 처리 및 고려 사항:**

*   **API 할당량 (Quotas):** 댓글 관련 엔드포인트는 호출당 약 1 유닛의 할당량을 소모. 하지만 답글을 많이 가져오거나 페이징을 많이 할 경우 총 소모량이 커질 수 있음. `max_total_comments`와 `max_replies_per_comment` 설정을 통해 과도한 호출 방지.
*   **오류 핸들링:** `HttpError` 처리 중요. 특히 댓글 기능이 비활성화된 경우(`commentsDisabled` 오류 포함)를 감지하여 사용자에게 알리거나 해당 동영상 처리를 건너뛰어야 함. 할당량 초과(403) 오류도 처리.
*   **댓글 정렬:** `order` 매개변수(`relevance` 또는 `time`)에 따라 다른 댓글이 수집될 수 있음. 분석 목적에 맞는 정렬 방식 선택.
*   **데이터 정제:** 댓글 텍스트에는 이모지, 특수문자, 링크 등이 포함될 수 있음. NLP 분석 전에 목적에 맞게 정제 필요.
*   **답글 수집 비용:** 답글 수집(`comments.list`)은 최상위 댓글마다 추가적인 API 호출을 유발하므로 할당량 소모가 많아짐. 꼭 필요한 경우가 아니거나 분석 범위를 좁히려면 `FETCH_REPLIES=False`로 설정하거나 `max_replies_per_comment`를 낮게 설정.
*   **댓글 검토:** 유튜브는 스팸이나 부적절한 댓글을 자동으로 필터링하거나 보류할 수 있음. API로 가져오는 댓글은 이러한 필터링이 적용된 후의 결과일 수 있음.

**8. 다음 단계:**

*   개발 문서 6: 텍스트 데이터 전처리 및 NLP 키워드 추출 (YAKE, RAKE, KeyBERT 등 활용)

---

이제 동영상의 스크립트와 시청자 댓글이라는 두 가지 중요한 텍스트 데이터를 확보했습니다. 다음 단계에서는 이 텍스트 데이터들을 분석 가능한 형태로 가공하고, 다양한 NLP 라이브러리를 사용하여 핵심 키워드를 추출하는 방법을 다룰 것입니다.