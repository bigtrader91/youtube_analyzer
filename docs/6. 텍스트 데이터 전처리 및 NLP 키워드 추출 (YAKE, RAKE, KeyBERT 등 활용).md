
### **ê°œë°œ ë¬¸ì„œ 6: í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° NLP í‚¤ì›Œë“œ ì¶”ì¶œ (YAKE, RAKE, KeyBERT ë“± í™œìš©)**

**1. ëª¨ë“ˆ ëª©í‘œ:**

*   ì´ì „ ë‹¨ê³„ë“¤(ê°œë°œ ë¬¸ì„œ 4, 5)ì—ì„œ ì¶”ì¶œí•œ ìœ íŠœë¸Œ ë™ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ ë° ëŒ“ê¸€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ NLP ë¶„ì„ì— ì í•©í•˜ë„ë¡ ì „ì²˜ë¦¬(Preprocessing).
*   ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ NLP ë¼ì´ë¸ŒëŸ¬ë¦¬(YAKE, RAKE-NLTK, KeyBERT ë“±)ë¥¼ ì ìš©í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œ ë° í‚¤í”„ë ˆì´ì¦ˆ(Keyphrases)ë¥¼ ì¶”ì¶œ.
*   ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½˜í…ì¸  ì•„ì´ë””ì–´ ë°œêµ´, SEO ìµœì í™”, ì‹œì²­ì ê´€ì‹¬ì‚¬ íŒŒì•… ë“±ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ ì œê³µ.

**2. í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬:**

*   **í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬:**
    *   `re`: ì •ê·œ í‘œí˜„ì‹ì„ ì´ìš©í•œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±° (íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨ì§€, URL ë“±).
    *   `nltk`: ìì—°ì–´ ì²˜ë¦¬ íˆ´í‚·. í† í°í™”(Tokenization), ë¶ˆìš©ì–´(Stopwords) ì œê±° ë“±ì— ì‚¬ìš©.
    *   `konlpy` (í•œêµ­ì–´ ì²˜ë¦¬ ì‹œ ì„ íƒ): í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ ë° ëª…ì‚¬ ì¶”ì¶œ ë“±ì— ì‚¬ìš©. (ì„¤ì¹˜ê°€ ë‹¤ì†Œ ë³µì¡í•  ìˆ˜ ìˆìŒ)
    *   `spacy`: ê³ ê¸‰ ìì—°ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬. í† í°í™”, í’ˆì‚¬ íƒœê¹…(POS tagging), ê°œì²´ëª… ì¸ì‹(NER) ë“±ì— í™œìš© ê°€ëŠ¥.
*   **í‚¤ì›Œë“œ ì¶”ì¶œ:**
    *   `yake`: í†µê³„ì  íŠ¹ì§• ê¸°ë°˜ì˜ ë¹„ì§€ë„ í•™ìŠµ í‚¤ì›Œë“œ ì¶”ì¶œê¸°. ë¹„êµì  ê°„ë‹¨í•˜ê³  ë‹¤êµ­ì–´ ì§€ì›.
    *   `rake-nltk`: RAKE(Rapid Automatic Keyword Extraction) ì•Œê³ ë¦¬ì¦˜ì˜ NLTK ê¸°ë°˜ êµ¬í˜„. êµ¬ë¬¸ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ.
    *   `keybert`: BERT ì„ë² ë”©ì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ. ë¬¸ë§¥ ì´í•´ë„ê°€ ë†’ìŒ. (GPU í™˜ê²½ì—ì„œ ë” ë¹ ë¦„)
    *   `pytextrank` (spaCy í™•ì¥): TextRank ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ í‚¤ì›Œë“œ ë° ìš”ì•½ ì¶”ì¶œ. ê·¸ë˜í”„ ê¸°ë°˜ ë°©ì‹.

**3. í•„ìˆ˜ ì…ë ¥:**

*   `text_data`: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°. ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” ëŒ“ê¸€ í…ìŠ¤íŠ¸ ë¬¸ìì—´, ë˜ëŠ” ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸. (e.g., `[script_text_1, comment_text_1, comment_text_2, ...]`)
*   (ì„ íƒ) `language`: í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ ì½”ë“œ (e.g., 'ko', 'en'). ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •ì— í•„ìš”.
*   (ì„ íƒ) `top_n`: ì¶”ì¶œí•  ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜.

**4. ì£¼ìš” êµ¬í˜„ ë‹¨ê³„:**

*   **(1) í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜:**
    *   ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë‹¤ìŒ ì‘ì—… ìˆ˜í–‰:
        *   ì†Œë¬¸ì ë³€í™˜ (ì˜ë¬¸ì˜ ê²½ìš°).
        *   ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ URL, ì´ë©”ì¼ ì£¼ì†Œ, í•´ì‹œíƒœê·¸, ë§¨ì…˜(@), ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨ì§€ ë“± ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±° ë˜ëŠ” ëŒ€ì²´.
        *   (í•œêµ­ì–´) `konlpy` ë“±ì„ ì´ìš©í•œ í˜•íƒœì†Œ ë¶„ì„ ë° ëª…ì‚¬/ë™ì‚¬ ë“± í•„ìš”í•œ í’ˆì‚¬ ì¶”ì¶œ.
        *   (ì˜ì–´) `nltk` ë˜ëŠ” `spacy`ë¥¼ ì´ìš©í•œ í† í°í™” ë° ë¶ˆìš©ì–´(stopwords) ì œê±°. (í•œêµ­ì–´ ë¶ˆìš©ì–´ ì‚¬ì „ë„ í•„ìš”ì‹œ ì§ì ‘ êµ¬ì¶• ë˜ëŠ” í™œìš©)
        *   (ì„ íƒ) í‘œì œì–´ ì¶”ì¶œ(Lemmatization) ë˜ëŠ” ì–´ê°„ ì¶”ì¶œ(Stemming) ìˆ˜í–‰.
    *   ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸(í† í° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì •ì œëœ ë¬¸ìì—´) ë°˜í™˜.
*   **(2) í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ (ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„):**
    *   **YAKE:**
        *   `yake.KeywordExtractor` ê°ì²´ ìƒì„± (ì–¸ì–´, ìƒìœ„ Nê°œ, ì¤‘ë³µ ì œê±° ë“± ì„¤ì •).
        *   `extractor.extract_keywords(processed_text)` í˜¸ì¶œ.
        *   ê²°ê³¼(í‚¤ì›Œë“œ, ì ìˆ˜) ë°˜í™˜.
    *   **RAKE-NLTK:**
        *   `rake_nltk.Rake` ê°ì²´ ìƒì„± (ë¶ˆìš©ì–´ ì‚¬ì „, êµ¬ë¬¸ ê¸¸ì´ ë“± ì„¤ì •).
        *   `rake.extract_keywords_from_text(processed_text)` í˜¸ì¶œ.
        *   `rake.get_ranked_phrases_with_scores()` ë¡œ ì ìˆ˜ì™€ í•¨ê»˜ í‚¤ì›Œë“œ(êµ¬ë¬¸) ì¶”ì¶œ.
    *   **KeyBERT:**
        *   `KeyBERT` ëª¨ë¸ ë¡œë“œ (ì‚¬ì „ í›ˆë ¨ëœ BERT ëª¨ë¸ ì§€ì •, e.g., 'bert-base-nli-mean-tokens' ë˜ëŠ” í•œêµ­ì–´ ëª¨ë¸ 'skt/kobert-base-v1').
        *   `model.extract_keywords(original_text, keyphrase_ngram_range, stop_words, top_n)` í˜¸ì¶œ. (KeyBERTëŠ” ì „ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì›ë¬¸ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì„ ìˆ˜ë„ ìˆìŒ).
        *   ê²°ê³¼(í‚¤ì›Œë“œ, ìœ ì‚¬ë„ ì ìˆ˜) ë°˜í™˜.
    *   **TextRank (pytextrank):**
        *   `spacy` íŒŒì´í”„ë¼ì¸ì— `pytextrank` ì¶”ê°€.
        *   `nlp(processed_text)` ì‹¤í–‰.
        *   `doc._.phrases` ì—ì„œ ì¶”ì¶œëœ í‚¤í”„ë ˆì´ì¦ˆ(ì ìˆ˜ í¬í•¨) ì ‘ê·¼.
*   **(3) í†µí•© ì‹¤í–‰ ë¡œì§:**
    *   ì…ë ¥ í…ìŠ¤íŠ¸ ë°ì´í„°(ìŠ¤í¬ë¦½íŠ¸, ëŒ“ê¸€ ëª¨ìŒ ë“±)ë¥¼ ì „ì²˜ë¦¬ í•¨ìˆ˜ì— ì „ë‹¬.
    *   ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ë¥¼ ê° í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ì— ì „ë‹¬.
    *   ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œì™€ ì ìˆ˜ë¥¼ ìˆ˜ì§‘.
*   **(4) ê²°ê³¼ ì·¨í•© ë° í›„ì²˜ë¦¬:**
    *   ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œë“¤ì„ ì·¨í•©.
    *   (ì„ íƒ) ì¤‘ë³µ ì œê±°, ì ìˆ˜ ê¸°ë°˜ ì •ë ¬, íŠ¹ì • í’ˆì‚¬ í•„í„°ë§ ë“± í›„ì²˜ë¦¬ ìˆ˜í–‰.
    *   ìµœì¢… í‚¤ì›Œë“œ ëª©ë¡ì„ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜ (e.g., `{'yake': [('í‚¤ì›Œë“œ1', 0.8), ...], 'rake': [('í‚¤ì›Œë“œ êµ¬ë¬¸', 15.0), ...], 'keybert': [('ë‹¤ë¥¸ í‚¤ì›Œë“œ', 0.9), ...]}`)

**5. ì½”ë“œ ìŠ¤ë‹ˆí« ì˜ˆì‹œ (í•µì‹¬ ë¡œì§ - ì˜ì–´ ê¸°ì¤€):**

```python
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
# nltk.download('punkt') # ìµœì´ˆ ì‹¤í–‰ ì‹œ í•„ìš”
# nltk.download('stopwords') # ìµœì´ˆ ì‹¤í–‰ ì‹œ í•„ìš”

import yake
from rake_nltk import Rake
from keybert import KeyBERT
# import spacy
# import pytextrank # spaCyì™€ pytextrank ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”

# --- 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì˜ì–´ ì˜ˆì‹œ) ---
stop_words_en = set(stopwords.words('english'))

def preprocess_text_en(text):
    """ì˜ë¬¸ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    if not isinstance(text, str): # ì…ë ¥ íƒ€ì… ì²´í¬
        return ""
    text = text.lower() # ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) # URL ì œê±°
    text = re.sub(r'\@\w+|\#','', text) # ë§¨ì…˜, í•´ì‹œíƒœê·¸ ì œê±°
    text = re.sub(r'[^\w\s]', '', text) # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°± ì œì™¸)
    text = re.sub(r'\d+', '', text) # ìˆ«ì ì œê±°
    tokens = word_tokenize(text)
    filtered_tokens = [word for word in tokens if word not in stop_words_en and len(word) > 1]
    return " ".join(filtered_tokens) # í† í°í™”ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ í•©ì³ì„œ ë°˜í™˜ (ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë¬¸ìì—´ ì…ë ¥ ì„ í˜¸)

# --- 2. í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ë“¤ ---
def extract_yake_keywords(text, language="en", top_n=10):
    """YAKEë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        kw_extractor = yake.KeywordExtractor(lan=language, n=1, dedupLim=0.9, top=top_n, features=None)
        keywords = kw_extractor.extract_keywords(text)
        return keywords # [('keyword', score), ...]
    except Exception as e:
        print(f"YAKE ì˜¤ë¥˜: {e}")
        return []

def extract_rake_keywords(text, top_n=10):
    """RAKE-NLTKë¡œ í‚¤ì›Œë“œ(êµ¬ë¬¸) ì¶”ì¶œ"""
    try:
        r = Rake()
        r.extract_keywords_from_text(text)
        keywords = r.get_ranked_phrases_with_scores()
        return keywords[:top_n] # [(score, 'keyword phrase'), ...] - ìˆœì„œ ì£¼ì˜!
    except Exception as e:
        print(f"RAKE ì˜¤ë¥˜: {e}")
        return []

def extract_keybert_keywords(original_text, top_n=10, model_name='all-MiniLM-L6-v2'):
    """KeyBERTë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    try:
        kw_model = KeyBERT(model=model_name)
        # KeyBERTëŠ” ë¶ˆìš©ì–´ ì œê±° ë“± ì¼ë¶€ ì „ì²˜ë¦¬ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰ ê°€ëŠ¥
        keywords = kw_model.extract_keywords(original_text,
                                             keyphrase_ngram_range=(1, 2), # 1~2 ë‹¨ì–´ êµ¬ë¬¸ ì¶”ì¶œ
                                             stop_words='english',        # ë‚´ë¶€ ë¶ˆìš©ì–´ ì‚¬ìš©
                                             use_maxsum=True,             # ê²°ê³¼ ë‹¤ì–‘ì„± ë†’ì´ê¸°
                                             nr_candidates=20,            # í›„ë³´ í‚¤ì›Œë“œ ìˆ˜
                                             top_n=top_n)
        return keywords # [('keyword', score), ...]
    except Exception as e:
        print(f"KeyBERT ì˜¤ë¥˜ ({model_name}): {e}")
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ ë“± ë°œìƒ ê°€ëŠ¥
        return []

# --- 3. í†µí•© ì‹¤í–‰ ë¡œì§ (ì˜ˆì‹œ) ---
if __name__ == "__main__":
    # ì´ì „ ë‹¨ê³„ì—ì„œ ê°€ì ¸ì˜¨ ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” ëŒ“ê¸€ í…ìŠ¤íŠ¸ (ì˜ˆì‹œ)
    sample_script = """
    Welcome back to the channel! Today, we're diving deep into Python programming,
    specifically focusing on data structures like lists and dictionaries.
    Understanding these fundamental concepts is crucial for any aspiring Python developer.
    We'll cover list comprehensions, dictionary methods, and common pitfalls.
    Make sure to subscribe for more Python tutorials and data science content!
    Check out the link in the description for the source code. #Python #DataScience
    Visit example.com for more info. Contact me@example.com
    This video got 1000 views! Amazing! ğŸ˜„
    """
    sample_comments = [
        "Great tutorial! Really helped me understand list comprehensions.",
        "What about sets and tuples? Can you make a video on those?",
        "Thanks! I was struggling with dictionary methods.",
        "Good explanation, but maybe cover nested dictionaries next time?",
        "Awesome content! subscribed ğŸ‘",
    ]

    # ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„
    print("--- ìŠ¤í¬ë¦½íŠ¸ ë¶„ì„ ---")
    processed_script = preprocess_text_en(sample_script)
    print(f"ì „ì²˜ë¦¬ëœ ìŠ¤í¬ë¦½íŠ¸: {processed_script[:200]}...") # ì¼ë¶€ë§Œ ì¶œë ¥

    yake_script_keywords = extract_yake_keywords(processed_script)
    rake_script_keywords = extract_rake_keywords(processed_script)
    keybert_script_keywords = extract_keybert_keywords(sample_script) # KeyBERTëŠ” ì›ë¬¸ ì‚¬ìš© ê°€ëŠ¥

    print("\nYAKE í‚¤ì›Œë“œ:", yake_script_keywords)
    print("RAKE í‚¤ì›Œë“œ/êµ¬ë¬¸:", rake_script_keywords)
    print("KeyBERT í‚¤ì›Œë“œ:", keybert_script_keywords)

    # ëŒ“ê¸€ ë¶„ì„ (ëª¨ë“  ëŒ“ê¸€ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ ë¶„ì„í•˜ê±°ë‚˜ ê°œë³„ ë¶„ì„ ê°€ëŠ¥)
    print("\n--- ëŒ“ê¸€ ë¶„ì„ (í†µí•©) ---")
    combined_comments = " ".join(sample_comments)
    processed_comments = preprocess_text_en(combined_comments)
    print(f"ì „ì²˜ë¦¬ëœ ëŒ“ê¸€: {processed_comments[:200]}...")

    yake_comment_keywords = extract_yake_keywords(processed_comments)
    rake_comment_keywords = extract_rake_keywords(processed_comments)
    keybert_comment_keywords = extract_keybert_keywords(combined_comments)

    print("\nYAKE í‚¤ì›Œë“œ:", yake_comment_keywords)
    print("RAKE í‚¤ì›Œë“œ/êµ¬ë¬¸:", rake_comment_keywords)
    print("KeyBERT í‚¤ì›Œë“œ:", keybert_comment_keywords)

    # --- 4. ê²°ê³¼ ì·¨í•© ë° í™œìš© (ì˜ˆì‹œ) ---
    # ê° ë°©ë²•ë³„ í‚¤ì›Œë“œë¥¼ ì¢…í•©í•˜ì—¬ ë¹ˆë„ ë¶„ì„, ì¤‘ìš”ë„ í‰ê°€ ë“± ìˆ˜í–‰ ê°€ëŠ¥
    all_extracted_keywords = {
        'script_yake': yake_script_keywords,
        'script_rake': rake_script_keywords,
        'script_keybert': keybert_script_keywords,
        'comment_yake': yake_comment_keywords,
        'comment_rake': rake_comment_keywords,
        'comment_keybert': keybert_comment_keywords,
    }
    # ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½˜í…ì¸  ì£¼ì œ ì„ ì •, íƒœê·¸ ì œì•ˆ, ì œëª© ì•„ì´ë””ì–´ êµ¬ìƒ ë“±ì— í™œìš©
    # ì˜ˆë¥¼ ë“¤ì–´, ëŒ“ê¸€ì—ì„œ ìì£¼ ì–¸ê¸‰ëœ 'sets', 'tuples', 'nested dictionaries'ëŠ” ë‹¤ìŒ ì˜ìƒ ì£¼ì œë¡œ ê³ ë ¤ ê°€ëŠ¥
```

**6. ë°ì´í„° ì¶œë ¥:**

*   ëª¨ë“ˆì€ ì…ë ¥ëœ í…ìŠ¤íŠ¸(ìŠ¤í¬ë¦½íŠ¸, ëŒ“ê¸€ ë“±)ì— ëŒ€í•´ ê° NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì¶”ì¶œí•œ í‚¤ì›Œë“œ(ë˜ëŠ” í‚¤í”„ë ˆì´ì¦ˆ)ì™€ í•´ë‹¹ í‚¤ì›Œë“œì˜ ì¤‘ìš”ë„ ì ìˆ˜(ì•Œê³ ë¦¬ì¦˜ë³„ ìƒì´)ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜. ë³´í†µ **ë”•ì…”ë„ˆë¦¬ í˜•íƒœ**ë¡œ ê° ì•Œê³ ë¦¬ì¦˜ì˜ ê²°ê³¼ë¥¼ ë‹´ì•„ ë°˜í™˜í•˜ëŠ” ê²ƒì´ ìœ ìš©.
*   ì´ ê²°ê³¼ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ê²€í† í•˜ì—¬ ì½˜í…ì¸  ì•„ì´ë””ì–´ë¥¼ ì–»ê±°ë‚˜, ë‹¤ë¥¸ ëª¨ë“ˆê³¼ ì—°ë™í•˜ì—¬ ìë™ íƒœê·¸ ìƒì„±, ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥ ë“±ì˜ ê¸°ëŠ¥ êµ¬í˜„ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŒ.

**7. ì˜¤ë¥˜ ì²˜ë¦¬ ë° ê³ ë ¤ ì‚¬í•­:**

*   **ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:** NLP ë¼ì´ë¸ŒëŸ¬ë¦¬, íŠ¹íˆ `konlpy`ë‚˜ `spaCy` ëª¨ë¸ ë“±ì€ ì„¤ì¹˜ ê³¼ì •ì´ ë‹¤ì†Œ ë³µì¡í•˜ê±°ë‚˜ ì˜ì¡´ì„± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ. ê°€ìƒ í™˜ê²½ ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥.
*   **ì–¸ì–´ ì§€ì›:** ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•¨. í•œêµ­ì–´ì˜ ê²½ìš° `konlpy`, í•œêµ­ì–´ BERT ëª¨ë¸(KeyBERTìš©) ë“±ì´ í•„ìš”. ì „ì²˜ë¦¬ ë‹¨ê³„(ë¶ˆìš©ì–´ ì‚¬ì „ ë“±)ë„ í•´ë‹¹ ì–¸ì–´ì— ë§ê²Œ ì¡°ì •í•´ì•¼ í•¨.
*   **ì „ì²˜ë¦¬ ì¤‘ìš”ì„±:** í‚¤ì›Œë“œ ì¶”ì¶œì˜ í’ˆì§ˆì€ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìˆ˜ì¤€ì— í¬ê²Œ ì˜í–¥ì„ ë°›ìŒ. ë¶„ì„ ëª©ì ê³¼ ë°ì´í„° íŠ¹ì„±ì— ë§ê²Œ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì‹ ì¤‘í•˜ê²Œ ì„¤ê³„í•´ì•¼ í•¨. ë„ˆë¬´ ë§ì€ ì •ë³´ë¥¼ ì œê±°í•˜ë©´ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ë†“ì¹  ìˆ˜ ìˆê³ , ë„ˆë¬´ ì ê²Œ ì œê±°í•˜ë©´ ë…¸ì´ì¦ˆê°€ ë§ì•„ì§.
*   **ì•Œê³ ë¦¬ì¦˜ íŠ¹ì„± ì´í•´:** ê° í‚¤ì›Œë“œ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ë¥¸ ì›ë¦¬ë¡œ ì‘ë™í•¨.
    *   YAKE/RAKE: í†µê³„/ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë¹„êµì  ë¹ ë¥´ì§€ë§Œ ë¬¸ë§¥ ì´í•´ ë¶€ì¡±.
    *   KeyBERT/TextRank: ì„ë² ë”©/ê·¸ë˜í”„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±ì´ë‚˜ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì§€ë§Œ ê³„ì‚° ë¹„ìš©ì´ ë” ë†’ì„ ìˆ˜ ìˆìŒ.
    *   ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ê³  ì¡°í•©í•˜ëŠ” ê²ƒì´ ë” ê°•ê±´í•œ ê²°ê³¼ë¥¼ ì–»ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŒ.
*   **ì„±ëŠ¥:** ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ê²½ìš°, íŠ¹íˆ KeyBERTì™€ ê°™ì´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ. GPU í™œìš© ë˜ëŠ” íš¨ìœ¨ì ì¸ ì½”ë“œ ì‘ì„± ê³ ë ¤.
*   **í‚¤ì›Œë“œ í’ˆì§ˆ í‰ê°€:** ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì‹¤ì œ ì½˜í…ì¸ ì˜ í•µì‹¬ ë‚´ìš©ì„ ì˜ ë°˜ì˜í•˜ëŠ”ì§€ëŠ” ì •ì„±ì ì¸ í‰ê°€ê°€ í•„ìš”í•¨. ì ìˆ˜ë§Œìœ¼ë¡œ íŒë‹¨í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ.

**8. ì¢…í•© ë° í–¥í›„ í™•ì¥ ë°©í–¥:**

*   ì§€ê¸ˆê¹Œì§€ ì‘ì„±ëœ ê°œë°œ ë¬¸ì„œ 1~6ì„ í†µí•´ Google/YouTube APIì™€ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í‚¤ì›Œë“œ ì¡°ì‚¬, ê²½ìŸ ë¶„ì„, ì½˜í…ì¸  í…ìŠ¤íŠ¸(ìŠ¤í¬ë¦½íŠ¸, ëŒ“ê¸€) ì¶”ì¶œ ë° í•µì‹¬ í‚¤ì›Œë“œ ë„ì¶œê¹Œì§€ì˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŒ.
*   **í–¥í›„ í™•ì¥ ë°©í–¥:**
    *   **ê²°ê³¼ ì‹œê°í™”:** ì¶”ì¶œëœ í‚¤ì›Œë“œ, ê²€ìƒ‰ëŸ‰ ì¶”ì´ ë“±ì„ ê·¸ë˜í”„ë‚˜ ì›Œë“œ í´ë¼ìš°ë“œë¡œ ì‹œê°í™”.
    *   **ê°ì„± ë¶„ì„:** ëŒ“ê¸€ í…ìŠ¤íŠ¸ì— ê°ì„± ë¶„ì„ì„ ì ìš©í•˜ì—¬ ì‹œì²­ì ë°˜ì‘(ê¸ì •/ë¶€ì •) íŒŒì•….
    *   **ì£¼ì œ ëª¨ë¸ë§ (Topic Modeling):** LDA ë“± ì£¼ì œ ëª¨ë¸ë§ ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìˆ¨ê²¨ì§„ ì£¼ì œ êµ¬ì¡° ë°œê²¬.
    *   **ì±„ë„ ë¶„ì„ í†µí•©:** YouTube Analytics APIë¥¼ ì—°ë™í•˜ì—¬ ì‹¤ì œ ì±„ë„ ì„±ê³¼ ë°ì´í„°(ì¡°íšŒìˆ˜, ì‹œì²­ ì‹œê°„, êµ¬ë…ì ë³€í™” ë“±)ì™€ í‚¤ì›Œë“œ/ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼ ë¹„êµ.
    *   **ì¸ë„¤ì¼ ë¶„ì„ ìë™í™”:** (ì£¼ì˜: ê¸°ìˆ ì  ì–´ë ¤ì›€) ê²½ìŸ ì˜ìƒ ì¸ë„¤ì¼ ì´ë¯¸ì§€ë“¤ì„ ìˆ˜ì§‘í•˜ê³ , ì´ë¯¸ì§€ ë¶„ì„ ê¸°ìˆ (ìƒ‰ìƒ ë¶„ì„, ê°ì²´ íƒì§€ ë“±)ì„ ì ìš©í•˜ì—¬ íŠ¸ë Œë“œ íŒŒì•… ì‹œë„.
    *   **ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤:** Streamlit, Flask/Django ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ.

---

ì´ ë¬¸ì„œ ì‹œë¦¬ì¦ˆëŠ” ë°ì´í„° ê¸°ë°˜ ìœ íŠœë¸Œ ì„±ì¥ì„ ìœ„í•œ ìë™í™” ë„êµ¬ ê°œë°œì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë“¤ì„ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” ê° ë‹¨ê³„ì˜ ì„¸ë¶€ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬, ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬, ê²°ê³¼ ì €ì¥ ë°©ì‹ ë“±ì„ ë”ìš± ê²¬ê³ í•˜ê²Œ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.